{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (1.42.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashish_sharma30\\onedrive - dell technologies\\desktop\\self learning project\\my_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#  !pip install openai requests python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# At first, add your api key to .env file as DEV_GENAI_API_KEY='Insert_your_Dev_GenAI_Text_to_Text_API_key_here' and load env file\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# alternatively you can export an enviroment variable using following command: export DEV_GENAI_API_KEY=\"Insert_your_Dev_GenAI_Text_to_Text_API_key_here\" \n",
    "\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "import os\n",
    "\n",
    "# As mentioned in the above Note try to setup Dell certificate in your environment to avoid verify=False(SSL verification is disabled).\n",
    "http_client=httpx.Client(verify=False)\n",
    "client = OpenAI(\n",
    "    base_url='https://genai-api-dev.dell.com/v1',\n",
    "    http_client=http_client,\n",
    "    api_key=os.environ[\"DEV_GENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashish_Sharma30\\OneDrive - Dell Technologies\\Desktop\\Self Learning project\\my_env\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'genai-api-dev.dell.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Los Angeles Dodgers are a Major League Baseball team based in Los Angeles, California. Established in 1883, they were originally called the Brooklyn Atlantics and later became the Brooklyn Dodgers before moving to Los Angeles in 1958. The Dodgers are known for their rich history, numerous Hall of Fame players, and winning tradition. They have won six World Series titles, 23 National League pennants, and 12 division titles. The team is also known for its iconic Dodger Stadium, which opened in 1962 and is the third-oldest ballpark in Major League Baseball. The Dodgers have a large and passionate fanbase, and their rivalry with the San Francisco Giants is one of the most storied in sports."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "streaming = True\n",
    "max_output_tokens = 200\n",
    "\n",
    "# Available Models list\n",
    "available_models = [\"mixtral-8x7b-instruct-v01\", \"llamaguard-7b\", \"mistral-7b-instruct-v03\", \"phi-3-mini-128k-instruct\", \"llama-3-8b-instruct\", \"llama-3-1-8b-instruct\"]\n",
    "\n",
    "# Let's select the model from available list\n",
    "model_selected = available_models[0]\n",
    "\n",
    "def stream_and_yield_response(response):\n",
    "    for chunk in response.iter_lines():\n",
    "        decoded_chunk = chunk.decode(\"utf-8\")\n",
    "        if decoded_chunk == \"data: [DONE]\":\n",
    "            pass\n",
    "        elif decoded_chunk.startswith(\"data: {\"):\n",
    "            payload = decoded_chunk.lstrip(\"data:\")\n",
    "            json_payload = json.loads(payload)\n",
    "            yield json_payload['choices'][0]['text']\n",
    "\n",
    "\n",
    "# function from confluence\n",
    "def llm_api(data):\n",
    "    \"\"\"\n",
    "    Create a request to Dev GenAI Text to Text model with API key in header.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://genai-api-dev.dell.com/v1/completions\"\n",
    "      \n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'api-key': os.environ[\"DEV_GENAI_API_KEY\"],\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "      \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data, stream=data['stream'], verify=False)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if data['stream']:\n",
    "            for result in stream_and_yield_response(response):\n",
    "                print(result, end='')\n",
    "        else:\n",
    "            response_dict = response.json()\n",
    "            result = response_dict['choices'][0]['text']\n",
    "            print(result)\n",
    "           \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print('Error code:', err.response.status_code)\n",
    "        print('Error message:', err.response.text)\n",
    "    except Exception as err:\n",
    "        print('Error:', err)\n",
    "\n",
    "# Model instruction and Parameters\n",
    "instruction_text = f'Can you explain who are the Los Angeles Dodgers and what are they known for is in less than {max_output_tokens} tokens?'\n",
    "  \n",
    "data = {\n",
    "    'prompt': instruction_text,\n",
    "    'temperature': 0.5,\n",
    "    'top_p': 0.95,\n",
    "    'max_tokens': max_output_tokens,\n",
    "    'stream': streaming,\n",
    "    'model': model_selected\n",
    "    }\n",
    "\n",
    "# API Call\n",
    "llm_api(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
